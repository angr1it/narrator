# Рефакторинг Narrator: переход от монолита к микросервисной архитектуре

## Текущее состояние монолита
В настоящее время сервис Narrator реализован как монолитное веб-приложение на FastAPI. Все
ключевые компоненты — TemplateService , SlotFiller , IdentityService ,
TemplateRenderer , GraphProxy и пр. — находятся в одном кодовом базе и вызываются
напрямую внутри процесса. Например, класс ExtractionPipeline прямо создаёт экземпляры этих
сервисов и использует их методы для обработки запроса .
Как работает текущий пайплайн: при вызове эндпоинта /extract-save создаётся объект
Pipeline, после чего выполняется серия шагов в одном процессе:
Поиск шаблонов: с помощью TemplateService по входному тексту ищутся подходящие
шаблоны CypherTemplate (хранятся во внешней базе Weaviate) .
Извлечение слотов: для каждого найденного шаблона компонент SlotFiller вызывает
LLM (например, OpenAI) и извлекает значения слотов из текста согласно схеме шаблона .
Разрешение сущностей (NER): извлечённые слоты передаются в IdentityService ,
который определяет идентификаторы сущностей для slot-значений, помеченных как ссылки
на сущности ( is_entity_ref ). Он либо находит существующие сущности, либо создаёт
новые записи (AliasRecord) в Weaviate для новых упоминаний .
Рендеринг Cypher: после заполнения слотов и разрешения сущностей шаблон объединяется
с данными – происходит рендеринг Jinja2-шаблона ( CypherTemplate.render ) через
TemplateRenderer . В результате получается текст Cypher-запроса для графовой БД (Neo4j),
включая привязку к узлу Chunk через chunk_id .
Запись в граф: сформированный Cypher-запрос исполняется через GraphProxy в Neo4j,
создавая/связывая узлы и отношения (например, узлы сущностей вроде Character, связи
MEMBER_OF, и связь MENTIONS с ChunkNode ) .
(Дополнительно) Raptor-индекс: вычисляются эмбеддинги текста и фактов для кластеризации
(RaptorNode), привязанные к ChunkNode (это вне рамок данного запроса, но уже реализовано
в монолите).
Все эти шаги сейчас жёстко связаны друг с другом внутри одного приложения. Компоненты
обмениваются сложными Pydantic-моделями (например, модель CypherTemplate описывает
шаблон и его слоты ) напрямую, что приводит к сильной взаимозависимости кода. Монолитная
архитектура затрудняет расширение и сопровождение: изменение в одном компоненте может
затронуть других, масштабировать отдельные части (например, вынести SlotFiller на отдельный
сервер) проблематично, и возникают сложности с управлением общими моделями данных (разными
частями кода используются одни и те же Pydantic-классы).
## Цели рефакторинга и микросервисная архитектура
Цель: разделить нынешний монолит на ряд изолированных микросервисов, каждый из которых
отвечает за свою часть функциональности. FastAPI-приложение при этом станет оркестратором
(координатором) бизнес-логики, а тяжёлые или независимые задачи будут выполнены
специализированными сервисами по запросу. Такая архитектура даст слабое связывание
компонентов, независимое масштабирование и облегчит работу с моделями данных.
Предлагается выделить следующие микросервисы (каждый будет запускаться в отдельном Dockerконтейнере):
TemplateService – сервис управления шаблонами. Отвечает за хранение и поиск шаблонов
CypherTemplate (например, в Weaviate). Предоставляет API для получения шаблона по
имени/ID, добавления/обновления шаблонов и семантического поиска top-K шаблонов по
входному тексту.
SlotFiller – сервис извлечения слотов. Инкапсулирует логику LLM: получает на вход текст и
описание шаблона (слоты), возвращает заполненные значения слотов. Он будет вызывать
внешние LLM (например, OpenAI API) и использовать внутренние шаблоны подсказок
(prompt'ы) для извлечения данных.
IdentityService – сервис разрешения сущностей (аналог NER+база alias-ов). Принимает на вход
заполненные слоты (особенно те, что являются ссылками на сущности, напр. имена
персонажей, названия фракций и т.п.) и возвращает уникальные идентификаторы для этих
сущностей. Он взаимодействует с хранилищем Alias (Weaviate) для поиска существующих
сущностей или сохранения новых alias-записей. Также этот сервис может выполнять
дополнительную логику (например, запросы к LLM для проверки alias'ов, как сделано сейчас).
(Опционально) GraphService – можно рассмотреть вынос взаимодействия с графовой БД
(Neo4j) в отдельный сервис. Однако, поскольку GraphProxy относительно прост и тесно
связан с оркестратором, его можно оставить внутри FastAPI-приложения. В текущем плане
FastAPI сам отправляет Cypher-запросы в Neo4j, поэтому отдельный сервис для этого не
требуется.
Оркестратор (FastAPI) останется единой точкой входа API. Он будет содержать минимальную
логику: получать входные запросы, вызывать необходимые RPC к микросервисам, собирать
результаты и реализовывать pipeline-логику (последовательность шагов) для каждого запроса.
Оркестратор также может выполнять небольшие вспомогательные задачи, такие как рендеринг
шаблона в конечный Cypher через TemplateRenderer и выполнение этого запроса в Neo4j через
GraphProxy . Таким образом, FastAPI выступает координатором: пайплайн реализован в
оркестраторе, а трудоёмкие подзадачи выполняются ассинхронно внешними сервисами.
Изоляция и независимость: Каждому микросервису соответствуют свои зависимости и модель
данных, по возможности без пересечения с другими. Например, TemplateService оперирует
объектами шаблонов и зависимостями для работы с Weaviate, SlotFiller – зависит от LLM и своих
prompt-шаблонов, IdentityService – от хранилища алиасов и, возможно, LLM для решений. Между
сервисами будет чётко определён контракт взаимодействия, чтобы избежать прямого импорта
внутренних классов одного сервиса в код другого. Это устраняет «головную боль» с Pydanticмоделями: общие структуры либо выносятся в отдельный модуль, либо (предпочтительно)
выражаются через стандартные схемы обмена (например, gRPC-сообщения).
Ниже описана предлагаемая реализация взаимодействия между сервисами с использованием gRPC
(Remote Procedure Call) и схема разделения моделей данных.
## RPC-взаимодействие через gRPC
Для эффективного и типобезопасного обмена данными между микросервисами предлагается
использовать gRPC. gRPC позволит определить строгие контракты (схемы сообщений и методов) для
каждого сервиса, а обмен будет происходить по высокопроизводительному бинарному протоколу. В
каждом сервисе будет поднят gRPC-сервер, а FastAPI-оркестратор будет вызывать их через
сгенерированные клиентские stubs.
Контракты (интерфейсы) микросервисов
Каждый сервис получит свой gRPC-интерфейс. Ниже схематично приведены методы и данные,
которые будут у каждого компонента (псевдокод на языке Protocol Buffers):
// Общие определения (например, common.proto)
message SlotDefinition {
string name = 1;
string type = 2; // "STRING", "INT", "FLOAT", "BOOL"
bool required = 3;
string description = 4;
bool is_entity_ref = 5;
string entity_type = 6;
string default_value = 7;
}
message Template { // Аналог CypherTemplate (без vector/pydanticspecific)
string id = 1; // UUID в строковом формате
string name = 2;
string title = 3;
string description = 4;
string category = 5;
repeated string keywords = 6;
repeated SlotDefinition slots = 7;
// ... прочие поля, например graph_relation, default_confidence, etc.
// (для простоты второстепенные поля опущены)
}
1. TemplateService (шаблоны):
service TemplateService {
rpc GetTemplate(GetTemplateRequest) returns (Template); //
получение шаблона по ID
rpc FindTemplates(FindTemplatesRequest) returns
(FindTemplatesResponse); // поиск top-K по тексту
rpc UpsertTemplate(UpsertTemplateRequest) returns (Template); //
добавление/обновление шаблона
}
message GetTemplateRequest { string template_id = 1; }
message FindTemplatesRequest {
string query = 1; // входной текст для поиска
string category = 2; // опциональный фильтр по категории
uint32 top_k = 3;
}
message FindTemplatesResponse {
repeated Template templates = 1;
}
message UpsertTemplateRequest {
Template template = 1; // данные шаблона для сохранения (без id для нового)
}
GetTemplate – вернёт полный шаблон по заданному UUID или имени.
FindTemplates – выполнит семантический поиск по базе шаблонов (с помощью embedдингов
или nearText в Weaviate) и вернёт список лучших шаблонов. По сути это аналог метода
top_k в текущем TemplateService .
UpsertTemplate – позволит создавать новый или обновлять существующий шаблон
(например, для административного API управления шаблонами).
2. SlotFiller (заполнение слотов):
service SlotFiller {
rpc FillSlots(FillSlotsRequest) returns (FillSlotsResponse);
}
message FillSlotsRequest {
Template template = 1; // Шаблон, слоты которого нужно заполнить
string text = 2; // Фрагмент входного текста
}
message SlotFillResult {
string template_id = 1;
map<string, string> slots = 2; // полученные значения слотов (имя ->
значение)
string details = 3; // вспомогательная информация (как
извлечено, отладочные данные)
}
message FillSlotsResponse {
repeated SlotFillResult fills = 1; // Возможен несколько наборов
заполненных слотов (multi-match)
}
Метод FillSlots принимает на вход описание шаблона (его структура слотов, описание и т.д.) и сырой
текст. В ответ возвращается один или несколько наборов заполненных слотов. Здесь для простоты
каждый слот-результат передаётся как строка ( map<string,string> slots ), хотя можно учесть
типы из SlotDefinition . Замечание: если важно сохранить типизацию (например, чтобы INT
приходил числом), вместо map<string,string> можно использовать более сложную схему
(например, message SlotValue { string name; oneof { string str_val; int32
int_val; ... } } ). Однако, для начала можно передавать все значения как строки, опираясь на
то, что тип слота известен из шаблона, и при необходимости оркестратор или IdentityService смогут
привести строку к нужному типу.
Внутри SlotFiller микросервис реализует ту же логику, что и прежний класс: формирует prompt'ы
(например, extract_slots.j2 , fallback_slots.j2 ) и вызывает LLM. Результат LLM парсится и
валидируется (например, с помощью Pydantic-моделей или аналогичного механизма), после чего
возвращается по RPC.
3. IdentityService (разрешение идентичности сущностей):
service IdentityService {
rpc ResolveSlots(ResolveSlotsRequest) returns (ResolveSlotsResponse);
rpc CommitAliases(CommitAliasesRequest) returns (CommitAliasesResponse);
rpc GetAliasMap(GetAliasMapRequest) returns (AliasMapResponse);
}
message ResolveSlotsRequest {
map<string, string> slots = 1; // заполенные слоты (имя ->
значение)
repeated SlotDefinition slot_defs =
2; // определения слотов (чтобы знать, какие являются entity_ref)
string chunk_id = 3; // идентификатор текущего фрагмента текста
(ChunkNode)
int32 chapter = 4; // контекст: номер главы или другой раздел текста
string snippet =
5; // исходный текстовый фрагмент (может использоваться для LLM или
логирования)
}
message ResolveSlotsResponse {
map<string, string> mapped_slots = 1; // изменённые/заменённые значения
слотов (например, имена -> уникальные ID)
repeated AliasTask alias_tasks = 2; // задачи на создание alias-записей
map<string, string> alias_map = 3; // карта entity_id -> alias_text
(для справки)
}
message AliasTask { // соответствует полям IdentityService.AliasTask
string cypher_template_id = 1;
string entity_id = 2;
string alias_text = 3;
string entity_type = 4;
int32 chapter = 5;
string chunk_id = 6;
string snippet = 7;
string details = 8;
}
message CommitAliasesRequest {
repeated AliasTask alias_tasks = 1;
}
message CommitAliasesResponse {
repeated string cypher_queries = 1; // опционально: Cypher для создания
AliasRecord связей (можно вернуть, либо выполнять внутри сервиса)
}
message GetAliasMapRequest { repeated string entity_ids = 1; }
message AliasMapResponse { map<string, string> alias_map = 1; }
Методы IdentityService: - ResolveSlots – принимает заполненные слоты и их описания, возвращает
результат разрешения идентичности. Здесь основная работа: проверить каждый слот, являющийся
ссылкой на сущность ( is_entity_ref = True ), найти в базе AliasRecord соответствующую
сущность или решить, что это новая сущность. Возвращается структура ResolveSlotsResponse ,
которая содержит: - mapped_slots : потенциально обновлённые значения слотов. Например, если
слот "character": "Арен" был распознан как уже известный персонаж с entity_id = 12345 , то
в mapped_slots этот слот может быть заменён на "character": "12345" (ID сущности). В
дальнейшем при рендеринге Cypher именно ID будут подставлены в графовые связи. -
alias_tasks : список задач по добавлению новых alias. Если найдены новые сущности,
IdentityService формирует задачи для их сохранения (включая поля alias_text, entity_type, связанный
template_id, chunk_id и др. по аналогии с текущим AliasTask в коде). - alias_map : словарь для
уже существующих соответствий entity_id -> alias_text (может использоваться, например,
позже для отображения имен вместо ID в ответах или для пост-обработки). - CommitAliases –
получает на вход список AliasTask (задач на сохранение alias) и выполняет их сохранение. В
текущем монолите метод commit_aliases в IdentityService сохраняет alias в Weaviate и формирует
Cypher-строки для привязки этих alias к графу . В микросервисе можно сделать так: - Либо
IdentityService сам сохранит алиасы в базу (Weaviate) и, к примеру, вернёт Cypher-запросы или
идентификаторы созданных алиасов. - Либо IdentityService просто сохранит в свою базу (Weaviate) и
не будет возвращать Cypher, а оркестратор не будет отдельно заниматься alias в графе (возможно,
привязка alias к ChunkNode уже делается в шаблонах chunk_mentions.j2 ). Тем не менее, для
полноты мы указали, что CommitAliasesResponse может возвращать список Cypher-запросов для
вставки alias-связей, которые оркестратор мог бы исполнить в Neo4j. Этот момент зависит от
реализации: если alias (AliasRecord) нужны только в Weaviate и не дублируются в графе, то можно
упростить и ничего не возвращать. - GetAliasMap – дополнительный метод для получения уже
известных alias по списку entity_id. Это соответствует уже реализованному методу get_alias_map
, который может потребоваться, например, после выполнения основных шагов, чтобы
сопоставить все найденные в графе идентификаторы с читаемыми именами.
## Реализация RPC в коде
На основе описанных контрактов будут подготовлены .proto -файлы для каждого сервиса. Эти
файлы затем компилируются генератором protoc для Python, что даст нам классы сообщений и stubклиентов/серверов.
Серверная часть для каждого микросервиса реализует интерфейс (Servicer). Например, для
TemplateService можно сделать так (псевдокод):
```python
# template_service_server.py
import grpc
from concurrent import futures
from proto import template_service_pb2, template_service_pb2_grpc
from template_logic import TemplateService # внутренний модуль с логикой
class
TemplateServiceServicer(template_service_pb2_grpc.TemplateServiceServicer):
def __init__(self):
# Инициализируем внутреннюю логику: подключение к Weaviate, embedder и
т.д.
self.svc = TemplateService(...)
def FindTemplates(self, request, context):
# Вызов внутреннего метода поиска
templates = self.svc.top_k(query=request.query,
category=request.category or None,
k=request.top_k or 10)
# Конвертируем результаты (список Pydantic-моделей CypherTemplate) в
список proto-объектов
resp_templates = []
for tpl in templates:
resp_templates.append(template_service_pb2.Template(
id=str(tpl.id),
name=tpl.name,
title=tpl.title,
description=tpl.description,
category=tpl.category or "",
keywords=tpl.keywords or [],
slots=[template_service_pb2.SlotDefinition(
name=slot.name, type=slot.type,
required=slot.required,
description=slot.description or "",
is_entity_ref=slot.is_entity_ref or False,
entity_type=slot.entity_type or ""
) for slot in tpl.slots.values()]
))
return
template_service_pb2.FindTemplatesResponse(templates=resp_templates)
# аналогично: GetTemplate, UpsertTemplate...
# Запуск gRPC сервера
server = grpc.server(futures.ThreadPoolExecutor(max_workers=4))
template_service_pb2_grpc.add_TemplateServiceServicer_to_server(TemplateServiceServicer(),
server)
server.add_insecure_port("[::]:50051")
server.start()
server.wait_for_termination()
```
Другие сервисы будут реализованы схожим образом: например, SlotFillerServicer будет принимать
запрос с шаблоном и текстом, внутри вызывать свою функцию (по аналогии с методом fill_slots
класса SlotFiller ) и формировать FillSlotsResponse . IdentityServiceServicer – обёртка над
методами resolve_bulk и commit_aliases существующей логики. Обратите внимание, как в
этом подходе внутри каждого сервиса мы можем продолжать использовать Pydantic-модели и
прочие инструменты, но они полностью инкапсулированы внутри сервиса. Во внешнее
взаимодействие выходят только простые структуры (строки, числа, списки) согласно контракту RPC.
Клиентская часть (оркестратор) будет вызывать микросервисы через сгенерированные stubклассы. Поскольку FastAPI работает асинхронно, удобно использовать асинхронный API gRPC (в
Python библиотека grpcio поддерживает asyncio). Пример того, как оркестратор может
взаимодействовать с TemplateService и другими:
```python
# orchestrator.py (фрагмент)
import grpc
from proto import template_service_pb2, template_service_pb2_grpc
from proto import slotfiller_pb2, slotfiller_pb2_grpc
from proto import identity_service_pb2, identity_service_pb2_grpc
from models import CypherTemplate, SlotFill # локальные Pydantic-модели или
общие
# Предположим, у нас есть ассинхронная функция обработки одного фрагмента:
async def process_fragment(text: str, chapter: int, tags: list[str]):
# 1. Поиск шаблонов
async with grpc.aio.insecure_channel("templateservice:50051") as channel:
template_stub = template_service_pb2_grpc.TemplateServiceStub(channel)
req = template_service_pb2.FindTemplatesRequest(query=text, top_k=5)
resp = await template_stub.FindTemplates(req)
templates = resp.templates # список Template (proto message)
results = [] # будем накапливать результаты для ответа
# 2. Для каждого шаблона извлекаем слоты
for template_msg in templates:
async with grpc.aio.insecure_channel("slotfiller:50052") as sf_channel:
sf_stub = slotfiller_pb2_grpc.SlotFillerStub(sf_channel)
sf_req = slotfiller_pb2.FillSlotsRequest(template=template_msg,
text=text)
sf_resp = await sf_stub.FillSlots(sf_req)
if not sf_resp.fills:
continue # если для данного шаблона ничего не получилось извлечь
fill = sf_resp.fills[0]
# берем только первый вариант заполнения (как в текущей логике)
# 3. Разрешение сущностей через IdentityService
async with grpc.aio.insecure_channel("identityservice:50053") as
id_channel:
id_stub = identity_service_pb2_grpc.IdentityServiceStub(id_channel)
res_req = identity_service_pb2.ResolveSlotsRequest(
slots=fill.slots,
slot_defs=template_msg.slots,
chapter=chapter, chunk_id="chunk-id", snippet=text
)
res_resp = await id_stub.ResolveSlots(res_req)
await
id_stub.CommitAliases(identity_service_pb2.CommitAliasesRequest(alias_tasks=res_resp.alias_tasks)# 4. Рендеринг Cypher на оркестраторе
# Конвертируем полученные данные обратно в Pydantic-модели для удобства
рендеринга
tpl_data = grpc_msg_to_dict(template_msg) # предположим функция
конвертирует proto->dict
template_obj = CypherTemplate(**tpl_data)
slot_fill_obj = SlotFill(template_id=fill.template_id,
slots=res_resp.mapped_slots, details=fill.details)
cypher_query = template_renderer.render(template_obj, slot_fill_obj,
meta={
"chunk_id": "chunk-id", "chapter": chapter,
"description": template_obj.description,
"confidence": template_obj.default_confidence, "score":
template_obj.score or 0.0
})
graph_proxy.run_query(cypher_query)
# выполнение в Neo4j (можно сделать асинхронно)
results.append({ "template": template_obj.name, "aliases":
res_resp.alias_map, "query": cypher_query })
return results
```
Примечание: код приведён для иллюстрации и не предназначен для запуска без
доработки. Здесь показано, как оркестратор может вызывать удалённые сервисы. В
реальном коде стоит оптимизировать повторное открытие каналов (например, держать
их открытыми в течение обработки запроса) и, возможно, выполнять некоторые
вызовы параллельно. Например, можно запускать несколько FillSlots запросов
одновременно для разных шаблонов через asyncio.gather , чтобы ускорить
обработку нескольких шаблонов.
Из приведённого псевдокода видна новая структура взаимодействия: FastAPI-оркестратор
запрашивает у TemplateService шаблоны, затем для каждого шаблона дергает SlotFiller, потом
полученные слоты отправляет в IdentityService, после чего сам занимается финальным рендерингом
и записью результатов. Эта логика соответствует прежнему порядку действий монолита, но теперь
каждый шаг – это асинхронный RPC вызов к отдельному сервису.
## Организация общих моделей и зависимостей
Главный вопрос при таком разделении – как организовать общие структуры данных (модели),
чтобы сервисы были независимы, и при этом не дублировать код без необходимости. В текущем
монолите классы вроде CypherTemplate , SlotDefinition , SlotFill определены один раз и
используются повсеместно, что в микросервисной архитектуре невозможно без общей зависимости.
Есть несколько подходов, и мы выбрали наиболее простой и понятный, связанный с gRPC:
Контракт как источник истины: Мы определяем структуры данных в .proto-схемах. Это
означает, что формат сообщений (Template, SlotDefinition, SlotFillResult, AliasTask и т.д.) описан
единожды, и на его основе для каждого сервиса генерируются классы. Каждый микросервис
оперирует proto-сообщениями на входе/выходе, а внутри может конвертировать их в свои
внутренние модели. Таким образом, формально общий код не шарится между сервисами —
каждый имеет свой сгенерированный класс Template или SlotDefinition , но эти классы
совместимы по данным. Это избавляет от прямой зависимости одного сервиса от кода другого.
Вынос Pydantic-моделей в отдельный пакет: Альтернативный вариант — создать
отдельную общую библиотеку (модуль), содержащую только определения моделей (например,
Pydantic BaseModel классы CypherTemplate , SlotDefinition , и пр.). Тогда и
TemplateService, и оркестратор, и другие могли бы устанавливать эту библиотеку и
использовать одни и те же классы. Однако такой подход всё же создаёт связь через общую
зависимость. Нужно будет версионировать эту библиотеку и синхронно обновлять во всех
сервисах при изменении схем. Это добавляет сложности в поддержке.
Прямое дублирование схем: можно оставить определения моделей в каждом сервисе, но
тогда надо вручную следить за их синхронизацией (чревато ошибками). Например,
SlotDefinition можно определять и в TemplateService, и в IdentityService отдельно. Это наименее
предпочтительно.
Мы рекомендуем первый подход (gRPC-контракты) как наиболее надёжный и явный. В нём Pydanticмодели используются только внутри сервисов по необходимости, а границы сервисов описаны
через proto-сообщения. Например, TemplateService хранит шаблоны в Weaviate и использует класс
CypherTemplate (Pydantic) внутренне для валидации/удобства, но наружу отдаёт proto- Template .
Оркестратор, получив Template по gRPC, при желании может сконвертировать его в свой Pydanticкласс CypherTemplate (у оркестратора может быть подключена та же схема моделей, например,
через общую библиотеку, либо он может собрать Pydantic-модель на лету из словаря). Такая
конверсия тривиальна, т.к. поля совпадают по именам. Например, можно использовать
google.protobuf.json_format :
```python
from google.protobuf.json_format import MessageToDict
tpl_dict = MessageToDict(template_proto) # конвертируем proto-сообщение
Template в обычный dict
cypher_template = CypherTemplate(**tpl_dict)
```
Теперь cypher_template – это полноценный Pydantic-объект, с методами вроде .render() , и его
можно передать в TemplateRenderer . Аналогично, после IdentityService мы собрали SlotFill
Pydantic-модель для удобства. Таким образом, оркестратор может использовать те же модели,
что и раньше, но они никуда не «утекают» наружу и не требуют, чтобы другие сервисы имели о них
представление. В других микросервисах (SlotFiller, IdentityService) внутри тоже могут применяться
Pydantic-модели для промежуточных шагов (например, распарсить JSON от LLM в Pydantic, как
сейчас), но на границе они преобразуются в простые структуры, определённые контрактом.
Такой способ организации значительно снижает связанность: микросервисы могут быть
реализованы на разных технологиях или версиях библиотек. Например, теоретически SlotFiller
можно переписать на другом языке – нужно лишь соблюсти контракт gRPC (схему сообщений). Даже
если все остаются на Python, у сервисов могут быть разные зависимости: TemplateService не
нуждается в библиотеках для LLM, а SlotFiller не зависит от драйвера Weaviate или Neo4j. Общее
между ними – только protobuf-схемы (и, возможно, базовые вещи вроде Pydantic, если они
используют общую модельную библиотеку, но это не обязательно).
Резюмируя, общие модели вынесены в независимый формат (proto). Благодаря этому отпадает
потребность «таскать» за собой Pydantic-классы между сервисами – достаточно поддерживать
консистентность контрактов. Если нужно изменить структуру, например добавить поле в
SlotDefinition , мы меняем .proto и пересобираем stubs; каждый сервис уже сам решит,
использовать ли это поле.
## Оркестрация и расширяемость
После разделения на микросервисы главный FastAPI-сервис будет выполнять лишь
координационные задачи. Его основные функции: - Предоставлять API конечным пользователям
(REST эндпоинты, например /extract-save остаётся, но его обработчик внутри теперь вызывает
RPC вместо прямого вызова методов классов). - Асинхронно вызывать удалённые сервисы согласно
пайплайну. FastAPI легко интегрируется с asyncio, а gRPC поддерживает асинхронные stubs, поэтому
все внешние запросы можно делать параллельно или последовательно, но без блокировки потоков. -
Собирать полученные результаты, выполнять небольшую пост-обработку. В нашем случае –
рендерить финальные Cypher-запросы и отправлять их в базу. Обратите внимание, рендеринг
( TemplateRenderer ) и выполнение запросов ( GraphProxy ) мы оставили в оркестраторе, так как
это быстрые операции, не требующие выделенного микросервиса. Это упрощает дизайн: FastAPI
сразу после получения ответов формирует Cypher и пишет в Neo4j, без дополнительных сетевых
вызовов. - Формировать окончательный ответ клиенту. Например, API может вернуть добавленный
chunk_id , raptor_node_id , а также какие факты/сущности были извлечены. Оркестратор
обладает всей информацией (шаблон, заполненные слоты, сопоставленные алиасы) для
формирования удобного ответа. Он может, к примеру, вернуть исходные имена сущностей
(используя alias_map из IdentityService) вместе с уникальными ID, чтобы фронтенд мог их отобразить.
Асинхронность и производительность. В новой архитектуре важно минимизировать задержки от
дополнительных сетевых вызовов. Использование gRPC помогает – он значительно быстрее REST/
HTTP за счёт бинарного формата и сжатия. К тому же, можно выполнять независимые запросы
параллельно. Например, если в пайплайне находится 5 шаблонов, оркестратор может одновременно
отправить 5 запросов SlotFiller (однако стоит учесть нагрузку на LLM/API ключ). Также можно не ждать
окончания CommitAliases для перехода к рендерингу следующего шаблона, а выполнять в
фоновом режиме (если допустить, что запись алиасов не влияет на основной результат немедленно).
Такие оптимизации возможны благодаря тому, что теперь компоненты разделены и общаются
асинхронно.
Масштабирование. Отдельные контейнеры позволяют масштабировать узкие места. Например,
если SlotFiller (связан с вызовами OpenAI) становится bottleneck, можно запустить несколько
экземпляров этого сервиса за балансировщиком. TemplateService может иметь свой масштаб
(например, если доступ к Weaviate тяжелый, можно поднять несколько экземпляров близко к нему).
Оркестратор тоже может масштабироваться (он без сохранения состояния, обрабатывает входящие
запросы). IdentityService при необходимости тоже масштабируется отдельно. Контейнеризация через
Docker упрощает деплой: можно использовать Docker Compose для локальной разработки, подняв
все сервисы и необходимые базы (Neo4j, Weaviate) в единой сети, или Kubernetes в продакшене для
управления несколькими экземплярами и обнаружения сервисов.
Docker Compose пример (концептуально):
```yaml
version: '3.8'
services:
orchestrator:
build: ./orchestrator
ports:
- "8000:8000"
environment:
- OPENAI_API_KEY=${OPENAI_API_KEY}
- WEAVIATE_URL=http://weaviate:8080
- WEAVIATE_API_KEY=${WEAVIATE_API_KEY}
- NEO4J_URL=neo4j://neo4j:7687
- NEO4J_USER=neo4j
- NEO4J_PASSWORD=...
depends_on:
- template_service
- slot_filler
- identity_service
- neo4j
- weaviate
template_service:
build: ./template_service
ports: ["50051:50051"]
environment:
- WEAVIATE_URL=http://weaviate:8080
- WEAVIATE_API_KEY=${WEAVIATE_API_KEY}
slot_filler:
build: ./slot_filler
ports: ["50052:50051"] # внутри контейнера порт 50051, публикуем как 50052
для уникальности
environment:
- OPENAI_API_KEY=${OPENAI_API_KEY}
# возможно, другие параметры (температура, модель и т.п.)
identity_service:
build: ./identity_service
ports: ["50053:50051"]
environment:
- WEAVIATE_URL=http://weaviate:8080
- WEAVIATE_API_KEY=${WEAVIATE_API_KEY}
- OPENAI_API_KEY=${OPENAI_API_KEY} # если IdentityService тоже
использует LLM для alias решений
neo4j:
image: neo4j:5
ports: ["7687:7687", "7474:7474"]
environment:
- NEO4J_AUTH=neo4j/password
weaviate:
image: semitechnologies/weaviate:latest
ports: ["8080:8080"]
environment:
- AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
- PERSISTENCE_DATA_PATH=/data
```
В этом примере указаны переменные окружения для соединения с внешними системами (Weaviate,
Neo4j, OpenAI). Каждый сервис запускается как независимый контейнер. Оркестратор может
обращаться к ним по имени контейнера ( template_service , slot_filler , ...) благодаря общей
Docker-сети. Например, templateservice:50051 в коде stub-а будет резолвиться на
соответствующий контейнер TemplateService.
Безопасность и управление конфигурацией: Поскольку сервисы выделены, можно разнести
конфигурацию. Например, OpenAI API ключ не нужен TemplateService, поэтому он ему не передаётся.
Доступы к базам тоже изолированы: TemplateService и IdentityService могут иметь доступ только к
Weaviate, а GraphProxy – только к Neo4j.
Логирование и отладка: Логи каждого сервиса независимы, что упрощает поиск узкого места.
Например, SlotFiller может логировать промпты и ответы LLM, не засоряя общий лог оркестратора.
Оркестратор будет логировать только высокоуровневый ход выполнения (например, какой шаблон
обработан, сколько фактов найдено и т.д.). В случае ошибки в конкретном сервисе, она не «роняет»
весь монолит – оркестратор может отловить исключение RPC, записать его и выдать частичный
результат или ошибку API, пока другие сервисы продолжают работать.
## Максимальное разнесение зависимостей
Одним из ключевых требований было минимизировать зависимости между микросервисами. В
предложенной архитектуре этого достигают следующие меры:
Отсутствие общего состояния: у каждого сервиса своя база или внешний ресурс. Например,
TemplateService и IdentityService оба используют Weaviate, но разные классы (коллекции)
внутри него ( CypherTemplate vs AliasRecord ) . Они не обращаются друг к другу
напрямую — только через оркестратор. Если нужно, можно даже разделить им доступ по
разным правам или инстансам баз (но в рамках этой системы это лишнее).
Контракты вместо внутренних моделей: ни SlotFiller, ни IdentityService не импортируют
класс CypherTemplate или SlotDefinition из кода TemplateService. Они оперируют либо
своими аналогичными классами, либо (как предложено) proto-сообщениями. Это устраняет
проблемы, когда изменение модели в одном месте требует менять код во всех сервисах.
Достаточно изменить определение сообщения и пересобрать — компилятор сообщит, если
что-то не соответствует новому формату.
Общая утилита моделей (опционально): если всё же решено использовать единые Pydanticмодели во всех сервисах, их логично вынести в отдельный пакет (например,
narrator_schemas ). Тогда будет единственная «общая зависимость», но сам
микросервисный код разных команд не пересекается. Мы предлагаем по возможности
избежать даже этого, но вариант допустим, особенно на первых этапах миграции: можно
временно подключить общий пакет моделей, чтобы быстрее реализовать RPC, а потом
постепенно от него отказаться, когда логика стабилизируется.
Изоляция библиотек: TemplateService, SlotFiller, IdentityService могут иметь конфликтующие
версии библиотек (например, разные версии langchain или weaviate-client ). В
монолите это вызвало бы конфликт, а в микросервисах – нет, каждый контейнер несёт свои
зависимости. Это даёт свободу развивать каждый компонент независимо. Главное, чтобы
интерфейс между ними оставался совместимым.
## Пошаговый план рефакторинга
Для наглядности опишем, какие изменения потребуется внести в кодовую базу Narrator при
переходе к такой архитектуре:
Выделение кодовой базы по сервисам: реорганизовать репозиторий. Например, можно
создать директории services/template_service , services/slot_filler , services/
identity_service , services/orchestrator . Распределить соответствующие модули:
В template_service переместить всё из app/services/templates и связанные схемы
( schemas/cypher.py для шаблонов). Оставить там только то, что нужно для работы с
шаблонами. Подготовить entrypoint (например, main.py ) для запуска gRPC-сервера.
В slot_filler поместить app/services/slot_filler.py , core/slots/prompts (Jinjaшаблоны для LLM), и связанные утилиты ( utils.helpers.llm , utils.helpers.sanitize
нужны SlotFiller). Настроить там запуск gRPC-сервера.
В identity_service вынести app/services/identity_service.py , core/identity/
prompts (если есть), и всё, что нужно для alias. Тоже свой сервер.
В orchestrator оставить FastAPI приложение: роуты (например, app/api/extract/ ), класс
Pipeline (можно слегка переделать под RPC), services/pipeline.py скорее всего
трансформируется или разбивается (возможно, отдельно ExtractionPipeline для orchestrator,
отдельно AugmentPipeline).
Общие утилиты ( utils/logger , модели schemas/slots.py , schemas/stage.py и т.п.) –
либо дублировать при необходимости, либо вынести в common модуль, которым могут
пользоваться все. Например, StageEnum (draft stage) может потребоваться в оркестраторе и
идентичном виде в IdentityService для отправки draft_stage – лучше вынести в контракт
или общую зависимость, или просто передавать как число/строку и локально
интерпретировать.
Разработка контрактов (proto): на основе схем Pydantic-моделей написать .proto файлы.
Можно один общий с разными service, либо по файлу на каждый сервис, но импортировать
общие определения. Например, common.proto с SlotDefinition , Template и др., а
template_service.proto , slot_filler.proto , identity_service.proto уже
определяют сервисы, импортируя сообщения из common. Сгенерировать код (можно встроить
в процесс сборки/деплоя).
Имплементация микросервисов:
В TemplateService вместо FastAPI роутов сделать gRPC методы. Логику методов взять из
существующего TemplateService класса. Например, метод FindTemplates вызывает
template_service.top_k и формирует ответ. Удалить/не использовать более app/
services/templates/service.py с зависимостями FastAPI. Теперь TemplateService –
самостоятельный процесс.
В SlotFiller микросервисе написать сервicer, который вызывает существующую функцию
fill_slots (или метод класса SlotFiller ). Возможно, придётся слегка изменить
интерфейс fill_slots – вместо принятия CypherTemplate (Pydantic) будет принимать
proto- Template или dict. Можно внутри сервиса конвертировать proto -> Pydantic для
минимальных изменений кода. Например, template =
```python
CypherTemplate(**MessageToDict(request.template)) – и далее использовать как
```
раньше.
В IdentityService микросервисе реализовать ResolveSlots через вызов
IdentityService.resolve_bulk синхронно (внутри asyncio to_thread, как сейчас это
делается), и CommitAliases через вызов commit_aliases . Обратить внимание на то, что
IdentityService в текущем коде создаётся с определёнными параметрами (Weaviate client,
callback_handler, LLM). Нужно будет обеспечить инициализацию, например, в __init__
сервиса создать подключение к Weaviate (аналог connect_to_weaviate из config) и,
возможно, настроить LLM (IdentityService использует ChatOpenAI для принятия решений). То
есть, внутри IdentityServiceServicer будет
```python
self.svc = IdentityService(wclient, embedder, llm=ChatOpenAI(...)) .
```
Доработка оркестратора:
Удалить или изолировать код, который больше не используется напрямую. Например, убрать
прямое создание TemplateService , SlotFiller и т.д. Вместо этого либо заменить эти
вызовы на RPC (как показано выше), либо внедрить слой-клиент. Можно сохранить класс
ExtractionPipeline , но его методы extract_and_save будут уже не сами вычислять, а
обращаться к stub-клиентам.
Настроить конфигурацию: адреса микросервисов (можно через переменные окружения или
файл). Например, TEMPLATE_SERVICE_HOST=template_service:50051 и т.п., чтобы в коде
оркестратора знать, куда стучаться.
Проверить, что возвращаемые через API данные остались полными. Вероятно, схема
ExtractSaveOut (ответ эндпоинта) можно оставить такой же, просто теперь мы можем
заполнить её данными из результатов. Например, если раньше возвращались
relationships и aliases , оркестратор может их сформировать: relationships – список
отношений (из результатов исполнения Cypher или из RenderPlan), aliases – список
alias_map или alias_info.
Тестирование и отладка: Протестировать каждый сервис отдельно (можно написать unitтесты на их внутренние методы или интеграционные, вызывая gRPC локально). Затем
протестировать end-to-end: поднять все сервисы (например, с помощью docker-compose) и
вызвать основной эндпоинт с различными примерами текста, сравнить результаты с
монолитной версией. Все метрики и побочные эффекты (запись в базу, создание узлов,
AliasRecord и т.п.) должны совпадать.
Расширение функциональности: с новой архитектурой будет проще добавить новые
возможности. Например, если нужно внедрить ещё один шаг в пайплайн (скажем,
дополнительную валидацию или обогащение данных), можно сделать новый микросервис
или расширить существующий, почти не затрагивая другие части. FastAPI-оркестратор просто
вызовет новый сервис в нужном месте. При увеличении нагрузки, как уже упоминалось,
можно масштабировать критичные микросервисы независимо.
## Преимущества предложенной архитектуры
Слабая связанность: компоненты ( TemplateService , SlotFiller , IdentityService )
больше не импортируют код друг друга. Они взаимодействуют только через хорошо
определённые контракты. Это облегчает понимание кода и уменьшает риск, что изменение в
одной части сломает другую.
Ясность ответственности: каждый сервис отвечает за свою область (Single Responsibility).
Можно вносить изменения или оптимизации локально. Команда разработки может работать
параллельно над разными сервисами без конфликтов.
Упрощение управления моделями: проблема общего класса CypherTemplate решается
либо выделением его в отдельный модуль, либо, что ещё лучше, заменой на понятие
"сообщение Template в контракте". Таким образом, не надо бороться с зависимостями
Pydantic-моделей – формат обмена фиксирован в RPC. Pydantic остаётся инструментом для
валидации внутри сервисов, а не способом связи между ними.
Производительность и масштабируемость: gRPC обеспечивает эффективное
взаимодействие, а разделение на микросервисы позволяет масштабировать тяжелые
компоненты. Например, если извлечение слотов требует больше ресурсов (CPU для обработки
LLM ответов), можно выделить больше инстансов SlotFiller или разместить его на машине с
GPU. TemplateService, напротив, может требовать побольше памяти для кеширования
Weaviate-клиента и эмбеддингов, но мало CPU, и его можно масштабировать отдельно при
росте числа шаблонов.
Изоляция сбоев: сбой в одном микросервисе (например, упала связь с OpenAI в SlotFiller) не
приводит к падению всего приложения. Оркестратор может обрабатывать ошибки (таймауты,
исключения RPC) и, например, возвращать частичный результат или сообщение об ошибке
конкретного шага. Остальные функции при этом остаются доступными.
Возможность полиглота: хоть сейчас все сервисы на Python, архитектура допускает, что
разные части могут быть реализованы на подходящих языках. Например, если когда-нибудь
потребуется переписать SlotFiller на Go для производительности, или использовать C++
библиотеку для NLP – это можно сделать, просто реализовав тот же gRPC контракт. Другие
сервисы этого не заметят.
Подготовка к расширению системы: поскольку упоминается, что "планируется
расширение", такая декомпозиция облегчает добавление новых возможностей. FastAPI
останется оркестратором, и новые микросервисы можно встраивать аналогично. Это
масштабирование по функциональности: можно добавить, к примеру, микросервис для
summarization или translation, и orchestrator будет решать, вызывать его или нет в зависимости
от параметров запроса.
## Заключение
Предложенный рефакторинг переводит Narrator с монолитной архитектуры на микросервисную,
разнеся ключевые компоненты по отдельным сервисам. Мы разобрали, как реализовать это
разбиение шаг за шагом: - Выделили TemplateService, SlotFiller, IdentityService как независимые
микросервисы (Docker-контейнеры), каждый со своим RPC API. - Описали gRPC-контракты для
взаимодействия, позволяющие оркестратору асинхронно вызывать необходимые операции без
прямой зависимости от внутренних классов сервисов. - Рассмотрели проблему общих моделей
(например, CypherTemplate ) и предложили решение через общие схемы данных в RPC или вынос
моделей в отдельный модуль – это устраняет жёсткие зависимости и дублирование. - Привели
примеры кода и схемы, показывающие, как будет устроен вызов методов теперь (с использованием
stub-клиентов gRPC вместо прямого вызова методов Python-классов). - Обсудили контейнеризацию и
конфигурацию: каждый сервис запускается отдельно, что позволяет гибко настраивать окружение и
масштабировать. - Указали, что FastAPI-приложение остаётся координатором (оркестратором) — его
задача организовать pipeline из вызовов микросервисов и собрать итог. Это соответствует
требованию, чтобы FastAPI только оркестрировал, а бизнес-логику делегировал внешним сервисам. -
Наконец, мы убедились, что такая архитектура готова к будущим изменениям: добавить новый
сервис или модифицировать существующий контракт теперь намного проще, чем в монолите.
В результате, Narrator станет более модульным, поддерживаемым и масштабируемым. Компоненты
не будут "мешать" друг другу, а развитие каждого можно вести независимо, соблюдая контракт. Этот
рефакторинг требует значительных первоначальных усилий (разделение кода, настройка
инфраструктуры RPC), но окупится облегченным сопровождением и расширением системы в
долгосрочной перспективе.
