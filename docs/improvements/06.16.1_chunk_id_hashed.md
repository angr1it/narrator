# Chunk ID hashing

## Цель
Устранить дублирование связей при повторной обработке одинакового текста.

## Контекст
Сейчас `ExtractionPipeline` создаёт `chunk_id` на основе случайного UUID. Если один и тот же фрагмент отправить дважды, в графе появятся две копии одних и тех же связей.

## Мотивация
Использование случайных идентификаторов затрудняет идемпотентность и ведёт к росту данных.

## Польза
Хэширование текста позволяет повторно использовать существующий `Chunk`, избегая лишних узлов и рёбер.

## Планируемые изменения
- Генерировать `chunk_id` как `"chunk-" + sha1(text).hexdigest()[:16]`.
- Обновить тесты на стабильность идентификатора.

## Локация
`app/services/pipeline.py` метод `extract_and_save`.

## Альтернативы
Можно хранить таблицу соответствия текста и `chunk_id`, но хэширование проще и не требует БД.

## Деплой
Миграций не требуется.

## Проверка
Новый юнит-тест должен показывать одинаковый `chunk_id` для одинакового текста.

## Меры на будущее
Документировать логику вычисления идентификатора и покрыть тестами.

## Отчёт
После внедрения повторный вызов с тем же текстом не создаёт новые связи.
